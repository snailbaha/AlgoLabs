# AlgoLabs

Запускалось в Clion, писал на C++
Прогон всех трех алгоритмов на первой генерации с размерами: m = 2**x, x = [1..13], n = 2**13:
 
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/50716795-e2d2-4878-b9e5-7389b6c4806b)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/4658df30-3e57-4343-abac-c4d52841e1c4)


Результаты запуска:

![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/183c6a61-ef21-46ec-9200-fece7cda3423)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/227863a2-6470-4afc-b818-1140aff4ef0a)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/0c62afe9-5f11-4e7e-84db-30adee074292)

Прогон всех трех алгоритмов второй генерации с размерами: m = 2**x, x = [1..13], n = 2**13: 

![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/0136bde6-33ff-43b9-8e70-1ca89d58f1db)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/30a0da07-30db-4bb5-bff6-b1c53c943792)


Результат запуска:

![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/65d61ae2-b980-4375-838e-06c77a8567a6)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/59a60ab4-e5ee-4091-9401-27433676ecb5)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/a548ac71-e9b6-41fa-8780-779b99625139)



Выводы/тезисы/мысли

![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/4a92f837-db83-4e80-84ea-b6cb1f1db118)
![image](https://github.com/snailbaha/AlgoLabs/assets/128145814/6b5ba593-6be7-46c1-b036-b54c33ec9fe7)

   
Если мы рассмотрим оба графика, мы увидим, что алгоритм "Бинарный поиск" проявляет наилучшую эффективность на таблицах с небольшим количеством строк, однако с увеличением числа строк время выполнения этого алгоритма также увеличивается. Это связано с тем, что с увеличением числа строк увеличивается количество вызовов этого алгоритма. Это наглядно проявляется, если рассмотреть сложность данного алгоритма в данном случае: O(m*log n).

Анализируя первый график, можно заметить, что на этих данных самым быстрым алгоритмом является "Лесенка", но на более крупных данных "Лесенка + Экспоненциальный поиск" догоняет его. Это объясняется тем, что на небольших данных "Лесенка + Экспоненциальный поиск" затрачивает дополнительное время на запуск "Бинарного поиска", в то время как "Лесенка" просто проходит по лесенке. Однако на больших данных "Лесенка" становится менее эффективной.

Рассматривая второй график, можно увидеть, что на протяжении увеличения размеров матрицы наиболее эффективным алгоритмом для данных второго поколения является "Лесенка + Экспоненциальный поиск", за которым следует "Лесенка". Однако с увеличением размеров матрицы "Лесенка" начинает замедляться. Это происходит потому, что "Лесенка + Экспоненциальный поиск" ускоряет обычную "Лесенку" благодаря "Экспоненциальному поиску" при спуске по строкам.
